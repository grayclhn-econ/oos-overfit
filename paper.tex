\documentclass[12pt,draft]{article}
\input{setup}

\title{Out-of-Sample Comparisons of Overfit Models}
\author{Gray Calhoun\thanks{email: gcalhoun@iastate.edu. I
    would like to thank Julian Betts, Helle Bunzel,
    St\'ephane Bonhomme, Marjorie Flavin,
    Nir Jaimovich, Lutz Kilian, Ivana Komunjer, Michael McCracken,
    Seth Pruitt, Ross Starr, Jim Stock, Yixiao Sun, Allan Timmermann,
    Hal White, several anonymous referees, participants at the 2010
    Midwest Economics Association Annual Meetings, the 2010
    International Symposium on Forecasting, the 2010 Joint Statistical
    Meetings, the 2011 NBER-NSF Time-Series
    Conference, and in many seminars at UCSD, and especially
    Graham Elliott for their valuable suggestions, feedback and advice
    in writing this paper.  I would also like to thank Amit Goyal for
    providing computer code and data for his 2008 RFS paper
    with Ivo Welch \citep{GoW:08}.} \\ Iowa State University}

\date{\VERSION}

\begin{document}
\maketitle

\begin{abstract}\noindent
  This paper uses dimension asymptotics to study the behavior of
  out-of-sample (OOS) test statistics when they are used to compare
  ``overfit'' linear regression models. Under these asymptotics, the
  number of predictors used by the larger model increases with the
  number of observations so that their ratio remains uniformly
  positive. This analysis gives a theoretical motivation for using
  out-of-sample (OOS) comparisons: the Diebold-Mariano-West OOS $t$-test
  (Diebold and Mariano, 1995, \textit{JBES}, and West, 1996,
  \textit{Econometrica}) allows a forecaster to conduct inference
  about the models' generalization error, an important measure of
  forecast accuracy that conditions on the models' parameter estimates.
  We show analytically and through Monte Carlo that standard full-sample
  test statistics can not test hypotheses about this measure of performance.
  Our paper also suggests that comparisons of overfit models require small
  OOS test samples. If $P$ denotes the number of observations used for the
  OOS comparison and $T$ the total number of observations, $P^2/T$ must
  converge to zero for the OOS $t$-test to be centered on the model's
  generalization error.

\noindent JEL Classification: C12, C22, C52, C53

\noindent Keywords: Generalization Error, Forecasting, Model
Selection, $t$-test, Dimension Asymptotics
\end{abstract}

\include{1-intro}
\include{2-setup}
\include{3-theory}
\include{4-montecarlo}
\include{5-goyalwelch}
\include{6-conclusion}

\appendix

\include{A1-support}
\include{A2-lemma}
\include{A3-lemma}
\include{A4-theorem}
\include{A5-theorem}
\include{A6-theorem}
\include{A7-theorem}

\include{B-tables}
\include{C-figures}

\bibliographystyle{abbrvnat}
\bibliography{latex-tools-0.2.1/references}

\include{D_supplemental}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% TeX-command-extra-options: "-shell-escape"
%%% End:

%  LocalWords:  ClM Mcc ClW MeR StW InK CCS CoS GiW GiR BRC HTF BoH '
%  LocalWords:  Tib BaN AIC BoB AkA AkP Efr iR eq FPE th Dou iS iT dx
%  LocalWords:  JoD ixz Mcl RHS MSE homoskedastic Joh Widom TrW Sil
%  LocalWords:  BFP dy LLNs VeR rlecuyer RSQLite Sar tikzDevice TikZ
%  LocalWords:  PGF LaTeX jt test's CaT Coc BRW LeN RaW RaZ LeR ZeH
%  LocalWords:  lmtest Zei dbframe Hmsic Har xtable Dah booktabs FeE
%  LocalWords:  Bonferroni BWB Gia MeP indices Schwarz HaH Jong i1 1R
%  LocalWords:  overcorrect 'X 's 2P i' 2i 2m 4C De eigenvectors 'M
%  LocalWords:  2'M 1'M DiM GoW Cla Whi RoW HHK Rde
