Limit Theory for Comparing Overfit Models Out-of-Sample
#+LaTeX_CLASS: beamer
#+AUTHOR: Gray Calhoun \newline Iowa State University
#+DATE: Joint Statistical Meetings \newline 3 August 2010
#+LaTeX_CLASS_OPTIONS: [presentation]
#+STARTUP: beamer
#+BEAMER_HEADER_EXTRA: \usecolortheme{dove} \usefonttheme[onlymath]{serif}
#+LaTeX_HEADER: \usepackage{setspace}
#+LaTeX_HEADER: \usepackage{nath}\renewcommand{\mathindent}{-1in}\frenchspacing
#+BEAMER_FRAME_LEVEL: 2
#+MACRO: h 2.4in
#+MACRO: w 4in
#+OPTIONS: toc:nil

* Introduction
** Introduction
   - Out-of-sample (~oos~) tests are popular but not well understood
   - Test hypotheses that can be tested over the full sample
     - e.g. Diebold and Mariano's (1995, JBES), West's (1996,
       Econometrica), and Clark and McCracken's (2001, J. Econometrics)
       (among others)
     - i.e. Inoue and Kilian's (2005 Econometric Rev., 2006 J
       Econometrics) point
     - Giacomini and White (2006) is an exception
   - This paper looks at the effect of "overfit" on out-of-sample
     comparison tests
   - Shows that ~oos~ comparisons can measure generalization error, which
     common in-sample tests can not.
** Structure of talk
   - Explain overfit and asymptotic theory
   - Specify the ~oos~ test
   - Present theoretical results
* How to think about overfit
** Overfit, Intuitively
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/overview-1.pdf]]
** Overfit, Intuitively
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/overview-2.pdf]]
** Overfit, Intuitively
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/overview-2b.pdf]]
* Discussion of asymptotic approach
** ~oos~ Comparison
# Estimated curve
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/overview-4.pdf]]
** ~oos~ Comparison
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/overview-5.pdf]]
** ~oos~ Test Statistic
   - Fundamentals
     - Let $y_{t+1}$ be the variable you want to predict
     - Let $x_{1t}$ and $x_{2t}$ be regressors for two different models.
       1) $y_{t+1} = x_{1t}'\theta_1 + \varepsilon_{1t}$
       2) $y_{t+1} = x_{2t}'\theta_2 + \varepsilon_{2t}$
     - The first model is the benchmark
     - Series are strictly stationary and absolutely regular
       - Moment conditions must hold as well
   - Observe $T$ total datapoints
     - Training Sample is the first $R$ observations
     - Test Sample is the last $P$ observations
     - $T = R+P$
** ~oos~ Test Statistic
   Interested in the difference in average forecasting performance over
   the test sample:
   \[ \bar D_1 \equiv P^{-1} \sum_{t=R}^{T-1} [L(y_{t+1} -
   x_{1t}'\hat\theta_{1R}) - L(y_{t+1} -
   x_{2t}'\hat\theta_{2R})]\]
   - Researcher will use $\sqrt{P} \bar D_1 / \hat\sigma$ to choose
     between the models
     - $\hat\sigma^2$ is an ~oos~ estimate of the asymptotic variance
        of $\bar D_1$.
   - $\hat\theta_{iR} \equiv (\sum_{s=1}^{R-1} x_{is}x_{is}')^{-1}
     \sum_{s=1}^{R-1} x_{is} y_{i,s+1}$
   - $L$ is a known (smooth) loss function

** Motivation for Asymptotics
   - Under conventional asymptotics, these curves converge to their
     pseudo-true values
   - Most theoretical approaches replace the estimated curves with
     their limit and compare the performance of the pseudo true curves
     - Then account for uncertainty in estimating the curves
   - These limiting curves will be more accurate than the estimated curves
   - Conclusions may be misleading
** Motivation for Asymptotics
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/overview-5.pdf]]
** Motivation for Asymptotics
   #+ATTR_LaTeX: width={{{w}}},height={{{h}}}
   [[./slide-plots/asymptotics-1.pdf]]
** Motivation for Asymptotics
   - To prevent convergence, we let $K$ increase with $T$ so that
     $K/T$ remains positive  
   - If $K/T$ remains positive (Eicker 1963 Ann. Math. Stat., Huber
     1973 Ann. Stat.)
       - Distance between OLS coefficients and true values does not
         vanish.
       - OLS coefficient estimates are not asymptotically normal
* Results
** Lemma 3.2
   *Lemma 3.2:* Suppose $\lim K_2/T > 0$, $\hat\sigma > 0$, and
     stationarity, weak dependence, and moment conditions hold.  Then  
     \[\sqrt{P} \frac{\bar D_1 - E_R \bar D_1}{\hat\sigma} \to^d N(0,1)
     \quad\mbox{as}\quad P \to \infty\]
     - Holds even if the models are nested; $K/T$ nonzero ensures that
       the forecasts are different
     - Intuition similar to Giacomini and White (2006, Econometrica)
** Objective of the Forecaster's Analysis
   - After choosing a model, forecaster will 
     - Reestimate the model over the entire dataset
     - use the model for the next $Q$ periods
   - i.e. forecaster will be judged based on
     \[ \bar D_2 \equiv Q^{-1} \sum_{t=T}^{T+Q-1} [L(y_{t+1} -
     x_{1t}'\hat\theta_{1T}) - L(y_{t+1} - x_{2t}'\hat\theta_{2T})] \]
** Objective of the Forecaster's Analysis
   - $\bar D_2$ is unknown in period $T$
   - The forecaster should choose
     between the models using $E_T \bar D_2$.
     - $E_T \bar D_2$ is the difference in the models' /generalization
       error/ (see Hastie, Tibshirani and Friedman, 2009)
   - Want to control
     \[P[\operatorname{reject\ benchmark} \mid E_T \bar D_2 \leq 0]\]
** Theorem 3.1
   - *Theorem 3.1*: Under the previous assumptions,
     \[\sqrt{P} \frac{\bar D_1 - E_T \bar D_2}{\hat\sigma} \to^d N(0,1)
     \quad\mbox{if}\quad\frac{P^2}{T} \to 0 \mbox{ and } P = O(Q)\]
     - ~oos~ average lets forecasters test for equal generalization error
     - Common choices of $P$ can give misleading results
* Failure of F-test
** Failure of In-Sample Comparisons
   - Full-sample tests (i.e. F-test and Wald test) will not help
     select model with lower generalization error.
   - Suppose we have nested models
     \[y_{t+1} = x_{t}'\theta + \varepsilon_{1t},\\
     y_{t+1} = x_{t}'\theta + z_t'\gamma + \varepsilon_{2t}\]
   - Does a valid and unbiased test of $\gamma = 0$ control 
     \[P[\operatorname{reject\ benchmark} \mid E_T \bar D_2 \leq 0]?\]
** Failure of In-Sample Comparisons
   - If $\gamma = 0$ then $E_T \bar D_2 \leq 0$
     - Model 2 will be less accurate using estimated coefficients
     - Test of size $\alpha$ will choose model 2 only with probability\\
       less than $\alpha$
   - We can have $E_T \bar D_2 < 0$ even if $\gamma \neq 0$.
     - Test of size $\alpha$ will choose model 2 with probability\\
       higher than $\alpha$.
   - These tests will have $P[\operatorname{reject} \mid E_T \bar D_2
     \leq 0] > \alpha$
     - reject the benchmark model too often
* Conclusion
** Future Work
   - Relax $P^2/T \to 0$
   - Extend to other window schemes
   - Extend to other forecasting models

* COMMENT Variables and such
 LocalWords:  beamer STARTUP usecolortheme usefonttheme onlymath usepackage toc
 LocalWords:  setspace renewcommand mathindent frenchspacing OOS Diebold JBES
 LocalWords:  Econometrica McCracken's Inoue Giacomini ATTR Eicker OLS iid sqrt
 LocalWords:  varepsilon datapoints iR Reestimate Tibshirani operatorname leq
 LocalWords:  neq frac infty nath oos mbox
