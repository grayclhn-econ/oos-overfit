%% LyX 1.5.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

\usepackage{babel}
\makeatother

\begin{document}

\section*{Brief simulation - Gray Calhoun}


\subsection*{DGP and Forecasts}

The DGP is a trivariate AR(1):\begin{align*}
x_{t} & =0.3\cdot x_{t-1}+\varepsilon_{1t}\\
y_{t} & =0.1\cdot y_{t-1}+\varepsilon_{2t}\\
z_{t} & =0.3\cdot z_{t-1}+\varepsilon_{3t}\\
\left(\begin{array}{c}
\varepsilon_{1t}\\
\varepsilon_{2t}\\
\varepsilon_{3t}\end{array}\right) & \sim N\left(\mathbf{0},\mathbf{I}_{3}\right).\end{align*}
I construct two models to predict $y_{t}$. The first uses $x_{t-1}$
as the only predictor, the second uses four lags of $y_{t}$ and $z_{t}$
as predictors:

\begin{align}
\hat{y}_{1t}\left(\alpha\right) & =\alpha_{0}+\alpha_{1}x_{t-1}\label{eq:model1}\\
\hat{y}_{2t}(\beta) & =\beta_{0}+\beta_{1}z_{t-1}+\beta_{2}z_{t-2}+\beta_{3}z_{t-3}+\beta_{4}z_{t-4}\nonumber \\
 & \quad+\beta_{5}y_{t-1}+\beta_{6}y_{t-2}+\beta_{7}y_{t-3}+\beta_{8}y_{t-4}.\label{eq:model2}\end{align}



\subsection*{Test Statistic and Details}

We're interested in the behavior of \begin{equation}
\Delta\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)/\hat{\sigma}\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)\label{eq:teststat}\end{equation}
where $\hat{\alpha}_{R}$ and $\hat{\beta}_{R}$ are the OLS estimates
of the unknown coefficients in \eqref{eq:model1} and \eqref{eq:model2}
that use only the first $R$ observations in the data set. The random
functions $\bar{\Delta}$ and $\hat{\sigma}$ are defined as usual
-- $\bar{\Delta}$ is the pseudo-out-of-sample average,\[
\bar{\Delta}\left(\alpha,\beta\right)\equiv\frac{1}{P}\sum_{s=R+1}^{R+P}\left[\left(y_{s}-\hat{y}_{1s}\left(\alpha\right)\right)^{2}-\left(y_{s+1}-\hat{y}_{2s}\left(\beta\right)\right)^{2}\right],\]
and $\hat{\sigma}^{2}$ is a prewhitened Newey-West HAC estimator
of the variance of $\bar{\Delta}$. I generate 300 random samples
for each combination of $R$ and $P$ with $R$ taking the values
80, 240, and 480 and $P$ the values 40, 80, 240, and 480.


\subsection*{Size of West's Test Statistic}

West's theory implies that we could use the statistic \eqref{eq:teststat}
to test the null hypothesis\begin{equation}
H_{0}:\quad E\left(\left(y_{t}-\hat{y}_{1t}\left(\alpha^{*}\right)\right)^{2}\right)\geq E\left(\left(y_{t}-\hat{y}_{2t}\left(\beta^{*}\right)\right)^{2}\right)\label{eq:null}\end{equation}
against the one-sided alternative\[
H_{a}:\quad E\left(\left(y_{t}-\hat{y}_{1t}\left(\alpha^{*}\right)\right)^{2}\right)<E\left(\left(y_{t}-\hat{y}_{2t}\left(\beta^{*}\right)\right)^{2}\right),\]
where $\alpha^{*}$ and $\beta^{*}$ are the pseudo-true values for
models \eqref{eq:model1} and \eqref{eq:model2}. Since \eqref{eq:null}
is true for our DGP, we should expect that the statistic \eqref{eq:teststat}
would be less than $-1.288$ in fewer than $10\%$ of the simulations.
Table 1 lists the percent that were less than that value. Even for
rather large values of $P$ and $R$ the size is pretty bad.


\subsection*{Two Tables Supporting my Theory}

Since the theory I'm working on suggests that we should not focus
on the null hypothesis \eqref{eq:null}, we can't compare the size
directly. My theory implies that a better approximation is\begin{equation}
\left[\bar{\Delta}\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)-\mu\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)\right]/\hat{\sigma}\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)\xrightarrow{d}N\left(0,1\right)\label{eq:calrv}\end{equation}
with\[
\mu\left(\alpha,\beta\right)\equiv E\left[\left(y_{t}-\hat{y}_{1t}\left(\alpha\right)\right)^{2}-\left(y_{t}-\hat{y}_{2t}\left(\beta\right)\right)^{2}\right].\]
 For comparison, we can look at the number of simulations in which
the random variable in \eqref{eq:calrv} is less than the nominal
$10\%$ quantile, $-1.288$. Those percentages are listed in Table
2 and are close to the nominal level.

Finally, my approach also indicates that the random variable \begin{equation}
\frac{\bar{\Delta}\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)-\mu\left(\hat{\alpha}_{T},\hat{\beta}_{T}\right)}{\hat{\sigma}\left(\hat{\alpha}_{R},\hat{\beta}_{R}\right)}\label{eq:rv2}\end{equation}
should be standard normal if $P^{2}/R$ converges to zero as $P,R\to\infty$.
Table 3 gives the relevant quantiles for that random variable and
seems consistent with the theory.

%
\begin{table}[p]
\caption{West Statistic, Percentage of simulations less than nominal 0.10 quantile}


\begin{tabular}{cccccc}
 &  & \multicolumn{4}{l}{P}\tabularnewline
 &  & 40 & 80 & 240 & 480\tabularnewline
R & 80 & 0.33 & 0.43 & 0.63 & 0.78\tabularnewline
 & 240 & 0.24 & 0.19 & 0.26 & 0.41\tabularnewline
 & 480 & 0.17 & 0.14 & 0.17 & 0.18\tabularnewline
\end{tabular}
\end{table}


%
\begin{table}[p]
\caption{My RV 1 (eq. 5)- Percentage of Simulations less than nominal 0.10
quantile}


\begin{tabular}{cccccc}
 &  & \multicolumn{4}{l}{P}\tabularnewline
 &  & 40 & 80 & 240 & 480\tabularnewline
R & 80 & 0.15 & 0.11 & 0.10 & 0.12\tabularnewline
 & 240 & 0.16 & 0.11 & 0.10 & 0.13\tabularnewline
 & 480 & 0.15 & 0.12 & 0.12 & 0.10\tabularnewline
\end{tabular}
\end{table}


%
\begin{table}[p]
\caption{My RV 2 (eq. 6) - Percentage of Simulations less than nominal 0.10
quantile}


\begin{tabular}{ccllcc}
 &  & \multicolumn{4}{l}{P}\tabularnewline
 &  & 40 & 80 & 240 & 480\tabularnewline
R & 80 & 0.24 & 0.31 & 0.54 & 0.75\tabularnewline
 & 240 & 0.20 & 0.17 & 0.25 & 0.46\tabularnewline
 & 480 & 0.16 & 0.15 & 0.20 & 0.26\tabularnewline
\end{tabular}
\end{table}

\end{document}
